{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "afed8f19-36c6-444a-ba3a-5fda0ea29d90",
   "metadata": {},
   "source": [
    "# Concept Map + Quiz Creation\n",
    "- Created: 11 Feb 2024\n",
    "- Showcases how to create concept maps, and how to create quizzes using strictjson prompts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "4cffce7e-40d0-4f55-8484-596374751ef6",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from agentjo import *"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51093c34-f899-4aed-903f-04b9f0264e09",
   "metadata": {},
   "source": [
    "# Define Your LLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e398e6c2-5f2f-4552-83c9-04e148b0a702",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "69b765ff-cea4-4622-9631-14f72e397832",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def llm(system_prompt: str, user_prompt: str) -> str:\n",
    "    ''' Here, we use OpenAI for illustration, you can change it to your own LLM '''\n",
    "    # ensure your LLM imports are all within this function\n",
    "    from openai import OpenAI\n",
    "    \n",
    "    # define your own LLM here\n",
    "    client = OpenAI()\n",
    "    response = client.chat.completions.create(\n",
    "        model='gpt-4o-mini',\n",
    "        temperature = 0,\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": system_prompt},\n",
    "            {\"role\": \"user\", \"content\": user_prompt}\n",
    "        ]\n",
    "    )\n",
    "    return response.choices[0].message.content"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67cb9063-05a6-4901-a373-c4dcbdb52650",
   "metadata": {},
   "source": [
    "# Generate Concept Maps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "e4f7ed00-7ee3-4f72-a067-232d8fedf43f",
   "metadata": {},
   "outputs": [],
   "source": [
    "text = '''In recent years, Large Language Models (LLMs) have been undergoing rapid iteration and\n",
    "evolution (Anthropic, 2024; Google, 2024; OpenAI, 2024a), progressively diminishing the gap\n",
    "towards Artificial General Intelligence (AGI).\n",
    "Recently, post-training has emerged as an important component of the full training pipeline.\n",
    "It has been shown to enhance accuracy on reasoning tasks, align with social values, and adapt\n",
    "to user preferences, all while requiring relatively minimal computational resources against\n",
    "pre-training. In the context of reasoning capabilities, OpenAI’s o1 (OpenAI, 2024b) series models\n",
    "were the first to introduce inference-time scaling by increasing the length of the Chain-ofThought reasoning process. This approach has achieved significant improvements in various\n",
    "reasoning tasks, such as mathematics, coding, and scientific reasoning. However, the challenge\n",
    "of effective test-time scaling remains an open question for the research community. Several prior\n",
    "works have explored various approaches, including process-based reward models (Lightman\n",
    "et al., 2023; Uesato et al., 2022; Wang et al., 2023), reinforcement learning (Kumar et al., 2024),\n",
    "and search algorithms such as Monte Carlo Tree Search and Beam Search (Feng et al., 2024; Trinh\n",
    "et al., 2024; Xin et al., 2024). However, none of these methods has achieved general reasoning\n",
    "performance comparable to OpenAI’s o1 series models.\n",
    "In this paper, we take the first step toward improving language model reasoning capabilities\n",
    "using pure reinforcement learning (RL). Our goal is to explore the potential of LLMs to develop\n",
    "reasoning capabilities without any supervised data, focusing on their self-evolution through\n",
    "a pure RL process. Specifically, we use DeepSeek-V3-Base as the base model and employ\n",
    "GRPO (Shao et al., 2024) as the RL framework to improve model performance in reasoning.\n",
    "During training, DeepSeek-R1-Zero naturally emerged with numerous powerful and interesting\n",
    "reasoning behaviors. After thousands of RL steps, DeepSeek-R1-Zero exhibits super performance\n",
    "on reasoning benchmarks. For instance, the pass@1 score on AIME 2024 increases from 15.6% to\n",
    "71.0%, and with majority voting, the score further improves to 86.7%, matching the performance\n",
    "of OpenAI-o1-0912.\n",
    "However, DeepSeek-R1-Zero encounters challenges such as poor readability, and language\n",
    "mixing. To address these issues and further enhance reasoning performance, we introduce\n",
    "DeepSeek-R1, which incorporates a small amount of cold-start data and a multi-stage training\n",
    "pipeline. Specifically, we begin by collecting thousands of cold-start data to fine-tune the\n",
    "DeepSeek-V3-Base model. Following this, we perform reasoning-oriented RL like DeepSeek-R1-\n",
    "Zero. Upon nearing convergence in the RL process, we create new SFT data through rejection\n",
    "sampling on the RL checkpoint, combined with supervised data from DeepSeek-V3 in domains\n",
    "such as writing, factual QA, and self-cognition, and then retrain the DeepSeek-V3-Base model.\n",
    "After fine-tuning with the new data, the checkpoint undergoes an additional RL process, taking\n",
    "into account prompts from all scenarios. After these steps, we obtained a checkpoint referred to\n",
    "as DeepSeek-R1, which achieves performance on par with OpenAI-o1-1217.\n",
    "We further explore distillation from DeepSeek-R1 to smaller dense models. Using Qwen2.5-\n",
    "32B (Qwen, 2024b) as the base model, direct distillation from DeepSeek-R1 outperforms applying\n",
    "RL on it. This demonstrates that the reasoning patterns discovered by larger base models are crucial for improving reasoning capabilities. We open-source the distilled Qwen and Llama (Dubey\n",
    "et al., 2024) series. Notably, our distilled 14B model outperforms state-of-the-art open-source\n",
    "QwQ-32B-Preview (Qwen, 2024a) by a large margin, and the distilled 32B and 70B models set a\n",
    "new record on the reasoning benchmarks among dense models.'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "63353aff-41f2-4f75-8874-a19352e59415",
   "metadata": {},
   "outputs": [],
   "source": [
    "res = strict_json('''Create a concept map of (Node 1, Node 2, relation), where relation is how Node 1 relates to Node 2.\n",
    "Keep the relation short and concise''',\n",
    "                  text,\n",
    "                  output_format = {\"Concept Map\": \"List of (Node 1, Node 2, relation), type: list\"},\n",
    "                  llm = llm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "7f2c05a1-abd4-401c-b9cd-66c6fe8bc70f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Concept Map': [['Large Language Models (LLMs)',\n",
       "   'Artificial General Intelligence (AGI)',\n",
       "   'diminishing gap towards'],\n",
       "  ['Post-training', 'Full training pipeline', 'important component of'],\n",
       "  ['Post-training', 'Accuracy on reasoning tasks', 'enhances'],\n",
       "  ['OpenAI’s o1 series models', 'Inference-time scaling', 'introduced by'],\n",
       "  ['Inference-time scaling',\n",
       "   'Chain-of-Thought reasoning process',\n",
       "   'increases length of'],\n",
       "  ['Chain-of-Thought reasoning process',\n",
       "   'Reasoning tasks',\n",
       "   'improves performance in'],\n",
       "  ['DeepSeek-V3-Base', 'DeepSeek-R1-Zero', 'base model for'],\n",
       "  ['DeepSeek-R1-Zero',\n",
       "   'Reasoning benchmarks',\n",
       "   'exhibits super performance on'],\n",
       "  ['DeepSeek-R1', 'Cold-start data', 'incorporates small amount of'],\n",
       "  ['DeepSeek-R1',\n",
       "   'Multi-stage training pipeline',\n",
       "   'enhances reasoning performance with'],\n",
       "  ['DeepSeek-R1', 'OpenAI-o1-1217', 'achieves performance on par with'],\n",
       "  ['Distillation', 'Smaller dense models', 'explores from DeepSeek-R1 to'],\n",
       "  ['Distilled Qwen',\n",
       "   'State-of-the-art open-source QwQ-32B-Preview',\n",
       "   'outperforms'],\n",
       "  ['Distilled models', 'Reasoning benchmarks', 'set new record on']]}"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "54ff7459-f90d-4976-998a-6942bd4d31d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "edges = res['Concept Map']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "3dd4c2a9-bc04-4e59-bcd5-503a8076688c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install pyvis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "9ee01820-8d84-4df7-a478-272c64f05290",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: When  cdn_resources is 'local' jupyter notebook has issues displaying graphics on chrome/safari. Use cdn_resources='in_line' or cdn_resources='remote' if you have issues viewing graphics in a notebook.\n",
      "interactive_knowledge_graph.html\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "        <iframe\n",
       "            width=\"100%\"\n",
       "            height=\"750px\"\n",
       "            src=\"interactive_knowledge_graph.html\"\n",
       "            frameborder=\"0\"\n",
       "            allowfullscreen\n",
       "            \n",
       "        ></iframe>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.lib.display.IFrame at 0x174b36ba0>"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pyvis.network import Network\n",
    "\n",
    "# Create the Pyvis Network instance.\n",
    "# Set notebook=False for scripts (set to True if in a Jupyter Notebook)\n",
    "net = Network(height=\"750px\", width=\"100%\", directed=True, notebook=True)\n",
    "\n",
    "# Set custom options to limit zoom range and enable dragging.\n",
    "# (These options are passed as a JSON string to vis.js.)\n",
    "net.set_options(\"\"\"\n",
    "var options = {\n",
    "  \"interaction\": {\n",
    "    \"dragView\": true,\n",
    "    \"zoomView\": true,\n",
    "    \"minZoom\": 0.5,\n",
    "    \"maxZoom\": 2\n",
    "  },\n",
    "  \"physics\": {\n",
    "    \"enabled\": true\n",
    "  },\n",
    "  \"layout\": {\n",
    "    \"improvedLayout\": true\n",
    "  }\n",
    "}\n",
    "\"\"\")\n",
    "\n",
    "# Add nodes to the network (avoid duplicates using a set)\n",
    "nodes = set()\n",
    "for source, target, _ in edges:\n",
    "    nodes.add(source)\n",
    "    nodes.add(target)\n",
    "\n",
    "for node in nodes:\n",
    "    net.add_node(node, label=node, title=node)\n",
    "\n",
    "# Add edges with labels (the label appears on the edge and on hover)\n",
    "for source, target, relation in edges:\n",
    "    net.add_edge(source, target, title=relation, label=relation)\n",
    "\n",
    "# === Inject custom JavaScript to prevent panning \"out-of-bounds\" ===\n",
    "#\n",
    "# This script listens for the \"dragEnd\" event on the network.\n",
    "# It calculates the bounding box (min/max positions) of all nodes.\n",
    "# If the current view center is too far (with a specified padding) from the bounding box,\n",
    "# it automatically calls network.fit() to recenter the graph.\n",
    "#\n",
    "# Adjust the \"padding\" value as needed.\n",
    "\n",
    "custom_script = \"\"\"\n",
    "<script type=\"text/javascript\">\n",
    "  network.on(\"dragEnd\", function () {\n",
    "    // Get positions of all nodes\n",
    "    var positions = network.getPositions();\n",
    "    var xs = [], ys = [];\n",
    "    for (var key in positions) {\n",
    "      xs.push(positions[key].x);\n",
    "      ys.push(positions[key].y);\n",
    "    }\n",
    "    var minX = Math.min.apply(null, xs);\n",
    "    var maxX = Math.max.apply(null, xs);\n",
    "    var minY = Math.min.apply(null, ys);\n",
    "    var maxY = Math.max.apply(null, ys);\n",
    "    \n",
    "    // Get the current view center of the network\n",
    "    var viewPosition = network.getViewPosition();\n",
    "    var centerX = viewPosition.x;\n",
    "    var centerY = viewPosition.y;\n",
    "    \n",
    "    // Define a tolerance (padding) around the nodes' bounding box\n",
    "    var padding = 50; // adjust this value as needed\n",
    "    \n",
    "    // If the center is out-of-bounds, recenter the network view.\n",
    "    if (centerX < minX - padding || centerX > maxX + padding ||\n",
    "        centerY < minY - padding || centerY > maxY + padding) {\n",
    "      network.fit({animation: {duration: 500}});\n",
    "    }\n",
    "  });\n",
    "</script>\n",
    "\"\"\"\n",
    "\n",
    "# Append the custom JavaScript to the HTML output.\n",
    "net.html += custom_script\n",
    "\n",
    "# Generate and open the interactive graph.\n",
    "net.show(\"interactive_knowledge_graph.html\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8967287f-06cd-4cee-8ebf-956ff9ac9be7",
   "metadata": {},
   "source": [
    "# Now Make it into a Quiz Game"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "0b84059c-af88-4d75-80be-fcb7f5bfdfc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "res = strict_json('''Generate questions and answers in multiple choice and the correct answer based on the text''',\n",
    "                  text,\n",
    "                  output_format = {\"Question 1\": \"type: str\",\n",
    "                                  \"Answers 1\": \"4 possible answers labelled A to D, only 1 correct, type: list\",\n",
    "                                  \"Correct Answer 1\": \"type: Enum['A','B','C','D']\",\n",
    "                                  \"Question 2\": \"type: str\",\n",
    "                                  \"Answers 2\": \"4 possible answers labelled A to D, only 1 correct, type: list\",\n",
    "                                  \"Correct Answer 2\": \"type: Enum['A','B','C','D']\",\n",
    "                                  \"Question 3\": \"type: str\",\n",
    "                                  \"Answers 3\": \"4 possible answers labelled A to D, only 1 correct, type: list\",\n",
    "                                  \"Correct Answer 3\": \"type: Enum['A','B','C','D']\",\n",
    "                                  \"Question 4\": \"type: str\",\n",
    "                                  \"Answers 4\": \"4 possible answers labelled A to D, only 1 correct, type: list\",\n",
    "                                  \"Correct Answer 4\": \"type: Enum['A','B','C','D']\",\n",
    "                                  \"Question 5\": \"type: str\",\n",
    "                                  \"Answers 5\": \"4 possible answers labelled A to D, only 1 correct, type: list\",\n",
    "                                  \"Correct Answer 5\": \"type: Enum['A','B','C','D']\"},\n",
    "                  llm = llm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "cd5879f7-a17d-40dd-87c3-dcd1fec1ff34",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Question 1': 'What is the main focus of the paper regarding language models?',\n",
       " 'Answers 1': ['A) Improving language model reasoning capabilities using supervised data',\n",
       "  'B) Exploring reasoning capabilities through pure reinforcement learning',\n",
       "  'C) Enhancing pre-training processes',\n",
       "  'D) Developing new computational resources'],\n",
       " 'Correct Answer 1': 'B',\n",
       " 'Question 2': 'What significant improvement was observed in DeepSeek-R1-Zero on the AIME 2024 benchmark?',\n",
       " 'Answers 2': ['A) Increase from 15.6% to 71.0% pass@1 score',\n",
       "  'B) Increase from 50% to 90% pass@1 score',\n",
       "  'C) Increase from 10% to 30% pass@1 score',\n",
       "  'D) No significant improvement was observed'],\n",
       " 'Correct Answer 2': 'A',\n",
       " 'Question 3': 'What challenges does DeepSeek-R1-Zero encounter?',\n",
       " 'Answers 3': ['A) High computational cost',\n",
       "  'B) Poor readability and language mixing',\n",
       "  'C) Lack of training data',\n",
       "  'D) Slow training speed'],\n",
       " 'Correct Answer 3': 'B',\n",
       " 'Question 4': 'What method is used to improve the performance of the DeepSeek-V3-Base model?',\n",
       " 'Answers 4': ['A) Supervised learning',\n",
       "  'B) Cold-start data and multi-stage training pipeline',\n",
       "  'C) Direct application of pre-trained models',\n",
       "  'D) Increasing computational resources'],\n",
       " 'Correct Answer 4': 'B',\n",
       " 'Question 5': 'What was the outcome of distilling from DeepSeek-R1 to smaller dense models?',\n",
       " 'Answers 5': ['A) No improvement in reasoning capabilities',\n",
       "  'B) Smaller models outperformed larger models',\n",
       "  'C) Distilled models set new records on reasoning benchmarks',\n",
       "  'D) Distillation was not successful'],\n",
       " 'Correct Answer 5': 'C'}"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80b54da0-5a50-4e87-a4ff-756f9876638c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
